{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.utils.data as utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"output.mp4\")\n",
    "ret, frame1 = cap.read()\n",
    "plt.imshow(frame1)\n",
    "\n",
    "'''\n",
    "cap = cv2.VideoCapture(cv2.samples.findFile(\"Test_Vid.mp4\"))\n",
    "output_w = 300\n",
    "output_h = 300\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "out = cv2.VideoWriter('output.mp4',fourcc, 30, (output_w,output_h))\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "  # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    " \n",
    "    # Display the resulting frame\n",
    "        #cv.imshow('Frame',frame)\n",
    "        height, width = frame.shape[0:2]\n",
    "        startRow = int(height*0)\n",
    "        startCol = int(width*.219)\n",
    "        endRow = int(height)\n",
    "        endCol = int(width*.781)\n",
    "        croppedImage = frame[startRow:endRow, startCol:endCol]\n",
    "        img = cv2.resize(croppedImage,(300, 300))\n",
    "        #cv2.imshow('img',img)\n",
    "        out.write(img)\n",
    "        # Press Q on keyboard to  exit\n",
    "        #if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        #    break\n",
    " \n",
    "  # Break the loop\n",
    "    else: \n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "out.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell only For creating training set \n",
    "\n",
    "X_dataset = []\n",
    "Y_dataset = []\n",
    "\n",
    "cap = cv2.VideoCapture(cv2.samples.findFile(\"output.mp4\"))\n",
    "i = -3\n",
    "prev_frame=None\n",
    "curr_frame=None\n",
    "while True:\n",
    "    i+=1\n",
    "    ret, next_frame = cap.read()\n",
    "    \n",
    "    #print(ret)\n",
    "    if ret: \n",
    "        \n",
    "        if prev_frame is None and curr_frame is None:\n",
    "            curr_frame = next_frame.copy()\n",
    "            continue\n",
    "            \n",
    "        if prev_frame is None:\n",
    "            prev_frame = curr_frame.copy()\n",
    "            curr_frame = next_frame.copy()\n",
    "            continue\n",
    "        \n",
    "        prev_gray = cv2.cvtColor(prev_frame,cv2.COLOR_BGR2GRAY)\n",
    "        curr_gray = cv2.cvtColor(curr_frame,cv2.COLOR_BGR2GRAY)\n",
    "        next_gray = cv2.cvtColor(next_frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        flow_prev_curr = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0) \n",
    "        flow_curr_next = cv2.calcOpticalFlowFarneback(curr_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0) \n",
    "        \n",
    "        flow_res = flow_curr_next - flow_prev_curr\n",
    "        \n",
    "        h, w = flow_curr_next.shape[:2]\n",
    "        flow = -flow_curr_next\n",
    "        flow[:,:,0] += np.arange(w)\n",
    "        flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "        generated_next_frame = cv2.remap(curr_frame, flow, None, cv2.INTER_LINEAR)\n",
    "        \n",
    "        actual_res = next_frame - generated_next_frame\n",
    "        \n",
    "        prev_frame = curr_frame.copy()\n",
    "        curr_frame = next_frame.copy()\n",
    "        \n",
    "        #inp = curr_frame, prev_frame, flow_prev_curr \n",
    "        #op = actual_res , flow_res\n",
    "         \n",
    "        inp = np.dstack( (prev_frame, flow_prev_curr, curr_frame) )\n",
    "        out = np.dstack( (actual_res, flow_res) ) \n",
    "        \n",
    "        #inp = np.dstack( (prev_frame, curr_frame) )\n",
    "        #out = np.dstack( (actual_res) )\n",
    "        \n",
    "        #print(out.shape)\n",
    "        X_dataset.append( inp )\n",
    "        Y_dataset.append( out )\n",
    "            \n",
    "        if i%100 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        if i==1500:\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset_np = np.array(X_dataset)\n",
    "Y_dataset_np = np.array(Y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sha = X_dataset_np.shape\n",
    "for i in range(8):\n",
    "    new = scale(X_dataset_np[:,:,:,i].reshape((sha[0],-1)), axis=0)\n",
    "    print(new.shape)\n",
    "    X_dataset_np[:,:,:,i] = new.reshape(sha[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset_np.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.array(dataset_for_training).shape)\n",
    "np.save( \"X_dataset_1500.npy\", X_dataset_np)\n",
    "np.save( \"Y_dataset_1500.npy\", Y_dataset_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1501, 8, 300, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = np.load(\"X_dataset_1500.npy\").transpose([0,3,1,2]) \n",
    "Y_data = np.load(\"Y_dataset_1500.npy\").transpose([0,3,1,2])\n",
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880.7383\n",
      "-886.66675\n"
     ]
    }
   ],
   "source": [
    "print(Y_data.max())\n",
    "print(Y_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1/0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntensor_x = torch.stack([torch.Tensor(i) for i in X_val])\\ntensor_y = torch.stack([torch.Tensor(i) for i in y_val])\\n\\nval_dataset = utils.TensorDataset(tensor_x,tensor_y)\\nval_loader = utils.DataLoader(train_dataset, batch_size=batch_size)\\n\\ntensor_x = torch.stack([torch.Tensor(i) for i in X_test])\\ntensor_y = torch.stack([torch.Tensor(i) for i in y_test])\\n\\ntest_dataset = utils.TensorDataset(tensor_x,tensor_y)\\ntest_loader = utils.DataLoader(train_dataset, batch_size=batch_size)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_data, Y_data, test_size=0.1/0.8, random_state=1)\n",
    "\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in X_train])\n",
    "tensor_y = torch.stack([torch.Tensor(i) for i in y_train])\n",
    "\n",
    "train_dataset = utils.TensorDataset(tensor_x,tensor_y)\n",
    "train_loader = utils.DataLoader(train_dataset, batch_size=batch_size)\n",
    "'''\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in X_val])\n",
    "tensor_y = torch.stack([torch.Tensor(i) for i in y_val])\n",
    "\n",
    "val_dataset = utils.TensorDataset(tensor_x,tensor_y)\n",
    "val_loader = utils.DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in X_test])\n",
    "tensor_y = torch.stack([torch.Tensor(i) for i in y_test])\n",
    "\n",
    "test_dataset = utils.TensorDataset(tensor_x,tensor_y)\n",
    "test_loader = utils.DataLoader(train_dataset, batch_size=batch_size)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, kernel, input_dim, output_dim):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        kernel = 3\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(8, 6, kernel_size=kernel),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(6, 6, kernel_size=kernel),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(6,16,kernel_size=kernel),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16,6,kernel_size=kernel),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(6,6,kernel_size=kernel),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(6,5,kernel_size=kernel))\n",
    "        #,\n",
    "        #    nn.Sigmoid())\n",
    "\n",
    "    def forward(self, images):\n",
    "        x = self.encoder(images)\n",
    "        #print(\"Model 10 : \",x.shape)\n",
    "        scores = self.decoder(x)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(8, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(16, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(6, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(6, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_size = 5\n",
    "model = Autoencoder(kernel_size, (300,300,8), (300,300,5))\n",
    "criterion = nn.MSELoss()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    c = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        images, targets = Variable(batch[0]), Variable(batch[1])\n",
    "        images, targets = images.cuda(), targets.cuda()\n",
    "        \n",
    "        output = model(images)\n",
    "        \n",
    "        loss = criterion(output, targets)\n",
    "        loss = torch.sqrt(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    print(\"Epoch : \",epoch, \" - Loss : \",loss)\n",
    "    '''\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            val_loss, val_acc = evaluate('val', n_batches=4)\n",
    "            train_loss = loss.data\n",
    "            examples_this_epoch = batch_idx * len(images)\n",
    "            epoch_progress = 100. * batch_idx / len(train_loader)\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t'\n",
    "                  'Train Loss: {:.6f}\\tVal Loss: {:.6f}\\tVal Acc: {}'.format(\n",
    "                epoch, examples_this_epoch, len(train_loader.dataset),\n",
    "                epoch_progress, train_loss, val_loss, val_acc))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1  - Loss :  tensor(86.7285, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  2  - Loss :  tensor(86.5280, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  3  - Loss :  tensor(86.2731, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  4  - Loss :  tensor(85.9771, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  5  - Loss :  tensor(85.6461, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  6  - Loss :  tensor(85.3205, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  7  - Loss :  tensor(84.9196, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  8  - Loss :  tensor(84.4799, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  9  - Loss :  tensor(84.1056, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  10  - Loss :  tensor(83.6519, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  11  - Loss :  tensor(83.0886, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  12  - Loss :  tensor(82.4944, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  13  - Loss :  tensor(82.1512, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  14  - Loss :  tensor(81.5549, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  15  - Loss :  tensor(80.9659, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  16  - Loss :  tensor(80.4708, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  17  - Loss :  tensor(80.0613, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  18  - Loss :  tensor(79.6101, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  19  - Loss :  tensor(79.2428, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  20  - Loss :  tensor(78.8493, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  21  - Loss :  tensor(78.4545, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  22  - Loss :  tensor(77.9458, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  23  - Loss :  tensor(77.4713, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  24  - Loss :  tensor(77.2007, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "Epoch :  25  - Loss :  tensor(77.1089, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "#0.001 64 - 77\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)# betas = (0.75, 0.9) )\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model( tensor_x[0:2].cuda() )\n",
    "op = output[0,:3,:,:].cpu().detach().numpy()\n",
    "print(op.shape)\n",
    "op = op.transpose([1,2,0])\n",
    "op.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tensor_x[0,0:3,:,:].cpu().detach().numpy().transpose([1,2,0]).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
